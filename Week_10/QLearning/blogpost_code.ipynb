{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u5gEsHBSYPZp",
        "outputId": "bce16661-d1a8-4337-b796-63db6983e5dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-Table:\n",
            "[[1671.64783365 1725.41997235 1510.6420359  1685.60490225]\n",
            " [1711.56610211 1710.70745557 1684.07250748 1711.88087577]\n",
            " [1699.81254363 1706.33262672 1712.79349296 1715.9476604 ]\n",
            " [1668.78945414 1724.03754207 1624.94217412 1716.41822964]\n",
            " [1711.55399327 1664.64148332 1684.02374693 1714.00826774]\n",
            " [1660.64571336 1725.41874098 1716.3691369  1535.6329528 ]\n",
            " [1716.32239865 1526.3116509  1616.02488461 1483.36021982]\n",
            " [1648.93151405 1716.40206159 1535.5385887  1687.88401366]\n",
            " [1689.76728955 1703.52213262 1727.23120436 1680.76086398]\n",
            " [1690.73975373 1722.94065702 1542.65281472 1630.29271729]\n",
            " [1637.71575133 1711.08557154 1680.94242993 1702.27849092]\n",
            " [1660.91803913 1650.70778167 1713.45668807 1675.24127454]\n",
            " [1647.06294777 1678.71908333 1674.01549544 1693.61715362]\n",
            " [1704.00785735 1692.79352614 1718.44200916 1634.43553402]\n",
            " [ 776.4566842  1714.01583111 1690.25598898 1529.41100509]\n",
            " [1713.95848958 1662.06531072 1573.75459662 1646.86262443]]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the grid world environment\n",
        "environment = np.array([\n",
        "    [-1, -1, -1, -1],    # 0 represents empty cells\n",
        "    [-1, -1, -1, -1],    # -1 represents obstacles\n",
        "    [-1, -1, -1, 100],   # 100 represents the goal state\n",
        "    [-1, -1, -1, -1]\n",
        "])\n",
        "\n",
        "# Set the parameters\n",
        "num_states = environment.size\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize the Q-table\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Perform Q-learning\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Choose an action using the epsilon-greedy strategy\n",
        "        if np.random.rand() < 0.5:\n",
        "            action = np.argmax(q_table[state])\n",
        "        else:\n",
        "            action = np.random.randint(0, num_actions)\n",
        "\n",
        "        # Perform the action and observe the new state and reward\n",
        "        new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "        reward = environment.flatten()[new_state]\n",
        "\n",
        "        # Update the Q-value of the previous state-action pair\n",
        "        q_table[state, action] += learning_rate * (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        # Check if the goal state is reached\n",
        "        if reward == 100:\n",
        "            break\n",
        "\n",
        "# Test the learned policy\n",
        "state = 0  # Starting state\n",
        "steps = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "    reward = environment.flatten()[new_state]\n",
        "\n",
        "    state = new_state\n",
        "    steps += 1\n",
        "\n",
        "    if reward == 100 or steps >= max_steps_per_episode:\n",
        "        done = True\n",
        "\n",
        "# Print the learned Q-table\n",
        "print(\"Learned Q-Table:\")\n",
        "print(q_table)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Define the grid world environment\n",
        "environment = np.array([\n",
        "    [-1, -1, -1, -1],    # 0 represents empty cells\n",
        "    [-1, -1, -1, -1],    # -1 represents obstacles\n",
        "    [-1, -1, -1, 100],   # 100 represents the goal state\n",
        "    [-1, -1, -1, -1]\n",
        "])\n",
        "\n",
        "# Define the symbols for different elements in the grid world\n",
        "symbols = {\n",
        "    -1: 'X',   # Obstacles\n",
        "    0: ' ',    # Empty cells\n",
        "    100: 'G'  # Goal state\n",
        "}\n",
        "\n",
        "# Set the parameters\n",
        "num_states = environment.size\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize the Q-table\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Perform Q-learning\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Choose an action using the epsilon-greedy strategy\n",
        "        if np.random.rand() < 0.5:\n",
        "            action = np.argmax(q_table[state])\n",
        "        else:\n",
        "            action = np.random.randint(0, num_actions)\n",
        "\n",
        "        # Perform the action and observe the new state and reward\n",
        "        new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "        reward = environment.flatten()[new_state]\n",
        "\n",
        "        # Update the Q-value of the previous state-action pair\n",
        "        q_table[state, action] += learning_rate * (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        # Check if the goal state is reached\n",
        "        if reward == 100:\n",
        "            break\n",
        "\n",
        "# Test the learned policy\n",
        "state = 0  # Starting state\n",
        "steps = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "    reward = environment.flatten()[new_state]\n",
        "\n",
        "    state = new_state\n",
        "    steps += 1\n",
        "\n",
        "    # Print the grid world with actors and agents\n",
        "    print(\"Grid World:\")\n",
        "    for i in range(environment.shape[0]):\n",
        "        for j in range(environment.shape[1]):\n",
        "            if (i * environment.shape[1] + j) == state:\n",
        "                print('A', end=' ')  # Agent\n",
        "            else:\n",
        "                print(symbols[environment[i, j]], end=' ')\n",
        "        print()\n",
        "    print()\n",
        "\n",
        "    if reward == 100 or steps >= max_steps_per_episode:\n",
        "        done = True\n",
        "\n",
        "# Print the learned Q-table\n",
        "print(\"Learned Q-Table:\")\n",
        "print(q_table)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6NtZzJ7CYZyp",
        "outputId": "303d0673-5e47-4a4f-cb46-3c7ca068f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Grid World:\n",
            "X X X X \n",
            "X X X X \n",
            "X X X A \n",
            "X X X X \n",
            "\n",
            "Learned Q-Table:\n",
            "[[1624.37586056 1555.17251255 1612.83239221 1639.73582757]\n",
            " [1639.86317319 1606.09514759 1340.54974434 1312.15679073]\n",
            " [1638.74036994 1575.59401587 1605.9930584  1517.94144333]\n",
            " [1639.75687329 1630.37985847 1536.12312878 1564.48692627]\n",
            " [1639.75697145 1626.98969707 1637.44819492 1624.07997622]\n",
            " [1630.48568573 1589.73059035 1586.9954774  1607.29252103]\n",
            " [1593.08038959 1639.9261784  1630.20705233 1609.18657335]\n",
            " [1552.51772724 1563.38250402 1592.40149965 1621.27928026]\n",
            " [1231.27620192 1557.21270629 1587.40363094 1639.9539211 ]\n",
            " [1638.74335934 1575.94308173 1609.54796582 1572.61163781]\n",
            " [1586.18037553 1540.70240632 1639.75776702 1601.2753151 ]\n",
            " [1526.71010751 1517.05699849 1408.44519774 1621.06123602]\n",
            " [1630.62253749 1572.63942363 1611.13155688 1611.00254468]\n",
            " [1622.09890997 1604.63410506 1629.85333154 1609.37754033]\n",
            " [1549.8983294  1369.96196165 1375.05576445 1629.80870112]\n",
            " [1590.11344867 1592.42394402 1535.93460157 1637.21376401]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the grid world environment\n",
        "environment = np.array([\n",
        "    [-1, -1, -1, -1],    # 0 represents empty cells\n",
        "    [-1, -1, -1, -1],    # -1 represents obstacles\n",
        "    [-1, -1, -1, 100],   # 100 represents the goal state\n",
        "    [-1, -1, -1, -1]\n",
        "])\n",
        "\n",
        "# Set the parameters\n",
        "num_states = environment.size\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize the Q-table\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Initialize the figure for visualization\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Function to plot the environment and actors\n",
        "def plot_environment(agent_state):\n",
        "    ax.clear()\n",
        "    ax.set_xticks(np.arange(-0.5, 4, 1))\n",
        "    ax.set_yticks(np.arange(-0.5, 4, 1))\n",
        "    ax.grid(True, linewidth=1, color='black')\n",
        "    ax.imshow(environment, cmap='gray', vmin=-1, vmax=100, interpolation='nearest', origin='upper')\n",
        "\n",
        "    # Plot the agent\n",
        "    agent_x, agent_y = agent_state % 4, agent_state // 4\n",
        "    ax.plot(agent_x, agent_y, marker='o', markersize=15, color='green', label='Agent')\n",
        "\n",
        "    # Plot the goal state\n",
        "    goal_state = np.where(environment.flatten() == 100)[0][0]\n",
        "    goal_x, goal_y = goal_state % 4, goal_state // 4\n",
        "    ax.plot(goal_x, goal_y, marker='*', markersize=15, color='yellow', label='Goal')\n",
        "\n",
        "    plt.legend(loc='upper right')\n",
        "    plt.draw()\n",
        "    plt.pause(0.1)\n",
        "\n",
        "# Perform Q-learning\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Choose an action using the epsilon-greedy strategy\n",
        "        if np.random.rand() < 0.5:\n",
        "            action = np.argmax(q_table[state])\n",
        "        else:\n",
        "            action = np.random.randint(0, num_actions)\n",
        "\n",
        "        # Perform the action and observe the new state and reward\n",
        "        new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "        reward = environment.flatten()[new_state]\n",
        "\n",
        "        # Update the Q-value of the previous state-action pair\n",
        "        q_table[state, action] += learning_rate * (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        # Check if the goal state is reached\n",
        "        if reward == 100:\n",
        "            break\n",
        "\n",
        "        # Plot the environment and actors\n",
        "        plot_environment(state)\n",
        "\n",
        "# Test the learned policy\n",
        "state = 0  # Starting state\n",
        "steps = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "    reward = environment.flatten()[new_state]\n",
        "\n",
        "    state = new_state\n",
        "    steps += 1\n",
        "\n",
        "    if reward == 100 or steps >= max_steps_per_episode:\n",
        "        done = True\n",
        "\n",
        "    # Plot the environment and actors\n",
        "    plot_environment(state)\n",
        "\n",
        "# Print the learned Q-table\n",
        "print(\"Learned Q-Table:\")\n",
        "print(q_table)\n",
        "\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "id": "VIyK4rQ8aBSo",
        "outputId": "d195236c-8bbb-4360-9528-93b39b7eb282"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAbsAAAGiCAYAAAB+sGhNAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAApW0lEQVR4nO3deXRV5b3/8c/ObIScgCQkSAhDIBW4SIgB0S7AFgeoiPVeBxQZVCgo60JFL9BVRfHaKHgdllqhuiCtiPZawbiclfGHIkKACwYMBgMBJCBDJgIZznl+fwSOBpKYkHNOyMP71fUse/Z+nr2/Z5vVT5999uAYY4wAALBYUHMXAACAvxF2AADrEXYAAOsRdgAA6xF2AADrEXYAAOsRdgAA6xF2AADrEXYAAOsRdgAA6/kt7I4ePaq77rpLUVFRio6O1r333qvS0tJ6xwwZMkSO49RokyZN8leJAIALhOOvZ2MOGzZMBw4c0IIFC1RZWanx48crLS1NS5YsqXPMkCFD1KNHD82ZM8e7LDIyUlFRUf4oEQBwgQjxx0Z37Nihjz/+WBs2bNAVV1whSXrxxRc1fPhwPfPMM+rQoUOdYyMjIxUXF+ePsgAAFyi/hN26desUHR3tDTpJGjp0qIKCgrR+/Xr9/ve/r3PsG2+8ocWLFysuLk4jRozQI488osjIyDr7l5eXq7y83PvZ4/Ho6NGjuuSSS+Q4jm++EAAgYIwxKikpUYcOHRQU5Jtf2/wSdgUFBYqNja25o5AQtW3bVgUFBXWOu/POO5WYmKgOHTpo69atmjFjhnJycrR06dI6x6Snp+vxxx/3We0AgPPD3r171bFjR99szDTCjBkzjKR6244dO8yTTz5pevTocdb4mJgY89e//rXB+1u+fLmRZHJzc+vsc/LkSVNUVORt+fn5v1gjjUaj0c7/VlhY2JiIqlejZnbTp0/XuHHj6u3TtWtXxcXF6dChQzWWV1VV6ejRo436PW7AgAGSpNzcXHXr1q3WPuHh4QoPD2/wNgEALYMvf4pqVNjFxMQoJibmF/sNHDhQhYWFysrKUmpqqiRpxYoV8ng83gBriC1btkiS4uPjG1MmAAA1+WyOeIYbbrjBpKSkmPXr15u1a9ea7t27m1GjRnnX79u3zyQnJ5v169cbY4zJzc01c+bMMRs3bjR5eXkmMzPTdO3a1QwaNKhR+y0qKmr2qTeNRqPRmt6Kiop8lkl+C7sjR46YUaNGmVatWpmoqCgzfvx4U1JS4l2fl5dnJJmVK1caY4zJz883gwYNMm3btjXh4eEmKSnJPPzww43+soQdjUaj2dF8GXZ+u6m8uRQXF8vlcjV3GQBaMMdxFB0drdatW3MLk4+ZU7cVFBYW6pfip6ioyGcPFfHLrQcA0FLFxMRo8uTJuuKKKxQSEtKosDPGaFfZLu0s3ak9J/aowlOhsKAwJV6UqB6teqhbZLcLPjyNMaqqqtKGDRs0f/58/fjjjwHZLzM7ADglJCRECxcuVJcuXRQREdHgcVWeKi3LX6Y3897U3rK91dtyQmRk5MhRlamSJCVEJmhUl1H6faffKyTowp5rnDx5Unl5ebrnnntUVVVVax9fzux46wEAnBIfH6927do1KuhyS3I1Zu0Yzc2e6w06SaoyVXIbtzfoJGlv2V7NzZ6rMWvHKLck16e1tzQRERFq165dwB4PSdgBwClBQUGNOs2YdSRL49aO0/el3zdqP9+Xfq9xa8cp60hWY0u0iuM4Cg4ODsi+CDsAOAe5Jbma+vVUVXgq5DbuRo11G7cqPBWa+vXUC36GFyiEHQA0UpWnSo9uflRVpkpG53bZg5FRlanS7M2zVeWp/Tcr+A5hBwCNtCx/mb4r+a7RM7ozuY1bO0t2aln+Mh9VhroQdgDQCMYYvZn3ps+258jRW7vf+sV7zhpi69atGjBggKZNm9b0ws7BDz/8oLS0NOXk5DTL/utD2AFAI+QU59S46rKpjIzyj+drZ/HOJm/rvffe02233abNmzcH7P61loKwA4A6GGN0oupEjbbl6Ba/7GvL0S019tPYmV5ZWZk+++wz/fu//7uuvvpqvf/++zXWr169WrfccouuvvpqTZo0Se+//77S0tJUUlLyUw1btmjChAn69a9/rd/97nd65plndOLECe/6m266SYsWLdKcOXM0ePBg3XjjjTXeNzpy5EhJ0ujRo5WWlqY//OEP53Io/OLCvqsRAOpx0n1Sgz4ZFJB9PbP9GT2z/Rnv5zXXr9FFIRc1ePznn3+uxMREde7cWcOGDdOzzz6rcePGyXEc7d+/XzNnztQdd9yhkSNHaufOnXrhhRdqjN+3b5/+8z//U5MmTdIjjzyiY8eOad68eZo7d65mz57t7ffGG2/oD3/4g8aPH6/ly5fr6aefVr9+/dS5c2dlZGRo3Lhxevnll9W1a1eFhoY2/cD4CDM7ALBAZmamhg0bJqn6NWulpaXatGmTJGnp0qVKTEzU1KlT1blzZ1133XW68cYba4zPyMjQDTfcoDvvvFOdOnXS5ZdfroceekgffvihysvLvf2uuuoq3XrrrUpISNDYsWMVHR2trKzq+wXbtGkjSXK5XGrXrt159TQrZnYAUIeI4AituX5NjWUv7HhBmXszazwZpalCnBCNTBipqZdNrbHvhtq9e7eys7M1b9686u2FhOjaa69VZmamUlNTlZ+fr549e9YYc+bnnTt3Kjc3Vx9//LF3mTFGHo9HP/zwg7p06SJJ6t69u3e94zi65JJLdPTo0YZ/2WZC2AFAHRzHOetUYo+oHj4NOqn60WI9XD0addry59577z253W4NHz7cu8wYo9DQUP3Xf/1Xg7Zx4sQJ3XLLLbr99tvPWvfzR3rV9sSTlvCIZcIOABqhZ3TPX+50Dnq5ep3TuKqqKn3wwQeaNm2aBgwYUGPdww8/rE8++USdOnXSl19+WWPd9u3ba3xOTk7W999/r4SEhHOqQ5L3NzqPx3PO2/AXfrMDgEZIjkpWQuS5B8KZHDnqdHEn9YjqcU7j165dq5KSEo0cOVJJSUk12m9+8xtlZmbqlltu0e7du/Xiiy9qz549+uyzz7xXa55+FujYsWO1detWzZ07Vzk5OcrPz9fq1as1d+7cBtfSpk0bhYeHa926dTpy5IhKS0vP6Tv5A2EHAI3gOI5GdRnls+0ZGd3R+Y5zfs9dZmam+vfvr1atWp217je/+Y127NihsrIyPfXUU1q5cqXuvPNOvfPOO7rnnnsk/TQb6969uxYsWKD8/HxNnDhRo0eP1oIFCxQTE9PgWkJCQvTQQw9p6dKlGj58uKZPn35O38kfeJ8dAJySmJio+fPnq127dvX2q/JUaczaMfq+9PsmPTIs2AlWt1bd9Pdf/z3g77dbuHCh3nnnHX3wwQcB3e/PHT58WJMmTdKePXtqXc/77ACgGYUEhWhOyhyFOCFydG4zMkeOQpwQPZ7yeECC7u2331Z2drb27dunDz/8UK+//vpZtx/YjAtUAOAcJLVO0gv9X9DUr6d6X9TaUMFOsEKcEL3Q/wUltU7yY5U/2bt3rxYuXKji4mLFxcXprrvu0rhx4wKy7/MBYQcA5yj1klRl/DpDszfP1s6SX362pSNHRkbdWnXT4ymPByzoJOnBBx/Ugw8+GLD9nW8IOwBogqTWSfr7r/+uZfnL9Gbem96HRIc4ITIycuR478tLuDhBd3S+Q7/v9PuA/0Z3oeNoA0AThQSF6NbOt+o/Ev9DO4t3KrsoW+6QLN2WskX/u7mvgqtS1cvVSz2iepzzVZdoGsIOAHzEcRwlu5KV7EpWhw4H1aHDp4oPTtAPP9zS3KVd8LgaEwD8IDr6/9X4J5oXYQcAPhYSckSRkd9JkiIjdyok5Px/ULLtCDsA8DGX66san6OivqqjJwKFsAMAH3O51srjqX47gMcTLJdrbTNX5Fs33XSTlixZ0txlNAoXqABAI4WGHlJoaF2nJo1crnUKCqq+yTwoyC2X60tFRu6Q6njaSmVlW1VWxja5rsOHDysjI0NffPGFDh06pFatWqljx44aNmyYbrzxRkVENPwdebYh7ACgkbp0ma2oqI11rjemZqgFB5epZ88xdfYvLk7Tzp1/bVJN+/bt03333afWrVvr/vvvV1JSkkJDQ7Vr1y4tW7ZMMTExGjx4cJP20ZIRdgBQJ6OgoJNnLT18eIQiI79VcHCparttznFMvZ+9WzeS291Khw/fqKCgEzXWeTwRqmsmWJunn35awcHB+sc//qGLLvrpJbAdO3bU4MGDvS9YLSgo0Lx587RhwwYFBQVp4MCBeuihh3TJJZdIqg7N5557Tt98841OnDihzp0764EHHjjrXXktDWEHAHUICjqpfv0G+W37jiOFhJSqa9fZkmbXWLdp0xp5PA17c3lhYaHWr1+v+++/v0bQ1dyXI4/Ho+nTpysyMlILFiyQ2+3W3Llz9ac//UkLFiyQJJWVlenqq6/W5MmTFRYWpg8++EDTp0/Xv/71rxpvLG9pCDsAaOH27dsnY4wSExNrLB86dKgqKiokSbfeeqv69++vXbt26d133/UG12OPPabbb79d2dnZ6tWrl3r06KEePX56kezkyZO1atUqrVmzRrfddlvgvpSPEXYAUAePJ0KbNq35xX4hIceUmPgXRUWtr/W05mnGSMXFA7Rnz59UVdXmF/fdVBkZGTLG6JFHHlFFRYXy8vLUvn37GjO0rl27qnXr1tq9e7d69eqlsrIy/e1vf9MXX3yhw4cPy+12q7y8XAUFBU2upzkRdgBQJ6dBpxIrKi7S8eO9Tl20Ut+rfoJ1/HhvVVR08FmFUvXvco7jnPUS1I4dO0qSwsPDG7ytF154QevXr9fUqVOVkJCg8PBwzZgxQ5WVlT6tOdC4zw4AfKD6sWC/9E47t18eHxYdHa0BAwbo7bff1okTJ+rs16VLFx08eLDGLO37779XSUmJunTpIkn6v//7P91444265pprlJSUpEsuuUQHDhzwec2BRtgBQBOFhBxWZOR3NU5hnr794Oe3ITjO6ceHHfF5DTNmzFBVVZXGjBmjTz/9VHl5edq9e7c+/PBD7d69W0FBQerfv7+6deumRx99VN9++62ys7P12GOPqV+/furZs6ckKSEhQStXrlROTo527typP//5z94rOVsyTmMCQBOd+XgwY4Lkdl+sQ4duV2zsPxUcXCbHcdfof+TI73xaQ8eOHfXGG29o0aJFevnll3Xo0CGFhYWpS5cuGj16tG699VY5jqP/+Z//0bx58zRx4sQatx6c9sc//lFPPPGE7r33XkVHR2vMmDE6fvy4T2ttDo6xIbJ/pri4WC6Xq7nLANACJSYmav78+WrXrl2jxnXtOktt2iyXVH1P3bFj12jPnpmqqmqrkJCjSkx8Sm3arDw1y3N09OhvlZf3Fz98g5bl8OHDmjRp0lm/NZ5WVFSkqKgon+yLmR0ANEmVXK51chyjqqrW2rNnlo4du/antVVttWvXXLVp85kSE9MVElIil+tLVf++F9xsVV9oCDsAaIKgoHKdPHmpKiou9c7manPs2LUqKUlVYuJTCgv7QUFBJ+XxXBzgai9chB0ANIHHc7F27PiHGjJLOz3LY1YXeFyNCQBN1tjgIugCjbADgFOMMVZcZt9SBPJ4E3YAcMqRI0e8z5KE/1VUVOjw4cMB2RdhBwCnHD9+XO+9954KCwubuxTrFRYW6r333lNZWVlA9scFKgDwM4sWLZIk3XTTTQoLC5NT35Od0WjGGFVUVOi9997zHutA4KZyAKhFZGSk2rVrR9j5mDFGhw8fbtCMjpvKAcDPysrKlJ+f39xlwEf4zQ4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPb+H3csvv6zOnTsrIiJCAwYM0Ndff11n34yMDDmOU6NFRET4u0QAgOX8Gnb//Oc/9eCDD2r27NnatGmTLr/8cl1//fU6dOhQnWOioqJ04MABb9uzZ48/SwQAXAD8GnbPPvusJkyYoPHjx6tnz56aP3++IiMjtXDhwjrHOI6juLg4b2vfvr0/SwQAXAD8FnYVFRXKysrS0KFDf9pZUJCGDh2qdevW1TmutLRUiYmJSkhI0MiRI5WdnV3vfsrLy1VcXFyjAQDwc34Lu8OHD8vtdp81M2vfvr0KCgpqHZOcnKyFCxcqMzNTixcvlsfj0VVXXaV9+/bVuZ/09HS5XC5vS0hI8On3AAC0fOfV1ZgDBw7UmDFj1LdvXw0ePFhLly5VTEyMFixYUOeYWbNmqaioyNv27t0bwIoBAC1BiL823K5dOwUHB+vgwYM1lh88eFBxcXEN2kZoaKhSUlKUm5tbZ5/w8HCFh4c3qVYAgN38NrMLCwtTamqqli9f7l3m8Xi0fPlyDRw4sEHbcLvd2rZtm+Lj4/1VJgDgQmD86K233jLh4eEmIyPDbN++3UycONFER0ebgoICY4wxd999t5k5c6a3/+OPP24++eQTs2vXLpOVlWXuuOMOExERYbKzsxu8z6KiIiOJRqPRaC28FRUV+SyP/HYaU5Juv/12/fjjj3r00UdVUFCgvn376uOPP/ZetJKfn6+goJ8ml8eOHdOECRNUUFCgNm3aKDU1VV9++aV69uzpzzIBAJZzjDGmuYvwpeLiYrlcruYuAwDQREVFRYqKivLJts6rqzEBAPAHwg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9v4bdmjVrNGLECHXo0EGO4+jdd9+tt/+qVavkOM5ZraCgwJ9lAgAs59ewO378uC6//HK9/PLLjRqXk5OjAwcOeFtsbKyfKgQAXAhC/LnxYcOGadiwYY0eFxsbq+jo6Ab1LS8vV3l5ufdzcXFxo/cHALDbefmbXd++fRUfH69rr71WX3zxRb1909PT5XK5vC0hISFAVQIAWgrHGGMCsiPH0bJly3TzzTfX2ScnJ0erVq3SFVdcofLycr322mt6/fXXtX79evXr16/WMbXN7Ag8AL62ePFiXXbZZc1dxgUhKytLEydOVFFRkaKionyyTb+exmys5ORkJScnez9fddVV2rVrl5577jm9/vrrtY4JDw9XeHh4oEoEcIG67LLL6vw/3fCt0tJSn2/zvDyN+XP9+/dXbm5uc5cBAGjBzvuw27Jli+Lj45u7DABAC+bX05ilpaU1ZmV5eXnasmWL2rZtq06dOmnWrFnav3+//vGPf0iSnn/+eXXp0kW9evXSyZMn9dprr2nFihX69NNP/VkmAMByfg27jRs36pprrvF+fvDBByVJY8eOVUZGhg4cOKD8/Hzv+oqKCk2fPl379+9XZGSk+vTpo88//7zGNgAAaKyAXY0ZKMXFxXK5XM1dBgDLZGVlcYFKgKxZs0aDBw/26dWY5/1vdgAANBVhBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsF5IcxcAAPAdY4w2F2zWhv0blP1jtk5UntBFoRepV0wvpV2appS4FDmO09xlBhxhBwAWqHRX6tVNr+r5r57Xd0e/kyNHqfHBmnNNlR5dGaKXvnbLyKh72+6aduU0Teg3QaHBoc1ddsBwGhMAWrhvDn2jtFfTNOXDKco9mitJMjK66VdVGtZdGpFcJSMjSco9mqspH05R2qtp+ubQN81ZdkARdgDQgq3evVr9X+2vbw59I3PqP6eN6FHzn5K8fb459I36v9pfq3evDnDFzYOwA4AW6ptD32jYG8NU7i6X27hrrIu9WOobV/3fU+KlmMiaY93GrXJ3uYa9MeyCmOERdgDQAlW6KzV66WhVuCvkMZ6z1l/f7YzPSWdvw2M8qvRUb6fSXemnSs8PhB0AtECvbnpVWw9uPWtGd9rw7lLlqVWVbml4LWEnSVWeKm09uFWvbnrVT5WeH7gaEwBaGGOM3tz2jFLifv4L3U8cRxqWJIUGV38ODa4Ov37xkqllgCOjN795RpOvmGztbQmEHQC0MJsLNuuxIXn6bde6+3jOCLXW4VLWxLr7f/59nrYUbFFKfIpvijzPcBoTAFqYDfs3aEGWdPRE7TM1SQpy6v98mjHV2/lblrThhw2+LfQ8QtgBQAuT/WO23v02VL96SVr6bfWyM2dyv+R0/6XfSr96SXr321BlH8r2baHnEcIOAFqYE5UnZGT0Y5n0H/8r3fa2VHhSqjr7osxaVXmq+9/2dvX4H8uq778rqyzzb+HNiLADgBbmotCL5Oin85Jvb6+enX26q+7TmqcZU93vVy9VjzvNkaPI0Mi6B7ZwhB0AtDC9YnqpylNVY9mPZVLWgV+e3bmNtPGH6v4/V+WpUq/YXj6u9PxB2AFAC5N2aZpqu+lgRA8p+Bf+Vz3Iqfn4sNOMjNI6pPmowvMPYQcALUxKXIq6t+1e41Rm+1OPB/v5VZenL0L5+cUrQU7148NiL/5pmSNHPS7pob5xff1beDMi7ACghXEcR9OunFZj2ZmPAzt9Ecrjq2u/eOXMx4lNHTDV2hvKJcIOAFqkCf0mqE/7Pgp2qh+TMixJcnt+msVl5lRfhPLYqup/ZuZUL/eY6n7DToVjSFCI+rTvo4mp9dxxbgHCDgBaoNDgUC2+ZbHCgsMUGuRoWFL173Vn3lIg6axbFIKDqh8fFhLkKDSoejshQXY/UIuwA4AWqndsb31010eKjghXXqH0zo6zbyn4udO3KLyzQ/r+mNQmIlwf3fWResf2DmjdzcHuKAcAyw3uPFgrxm7QmGV3aUvBtlNL677Z7nCZo1v/V+ob929aMfaNCyLoJGZ2ANDi9Y7trfX3bdRLw19SUtvqH+McVZ+iDAkKUWhQqPfKze6XdNdLw1/S+vs2XjBBJzGzAwArhAaH6v60+zX5isnaUrBFG37YoOxD2SqrLFNkaKR6xfZSWoc09Y3ra/VVl3Uh7ADAIo7jKCU+xdpX9ZwrTmMCAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArEfYAQCsR9gBAKxH2AEArOfXsEtPT1daWppat26t2NhY3XzzzcrJyal3TEZGhhzHqdEiIiL8WSYAwHJ+DbvVq1frgQce0FdffaXPPvtMlZWVuu6663T8+PF6x0VFRenAgQPetmfPHn+WCQCwXIg/N/7xxx/X+JyRkaHY2FhlZWVp0KBBdY5zHEdxcXH+LA0AcAHxa9idqaioSJLUtm3bevuVlpYqMTFRHo9H/fr101/+8hf16tWr1r7l5eUqLy/3fi4uLvZdwQBwSmpqanOXgCYI2AUqHo9H06ZN09VXX63evXvX2S85OVkLFy5UZmamFi9eLI/Ho6uuukr79u2rtX96erpcLpe3JSQk+OsrAABaKMcYYwKxo8mTJ+ujjz7S2rVr1bFjxwaPq6ys1GWXXaZRo0bpiSeeOGt9bTM7Ag8AWr6ioiJFRUX5ZFsBOY05ZcoUvf/++1qzZk2jgk6SQkNDlZKSotzc3FrXh4eHKzw83BdlAgAs5dfTmMYYTZkyRcuWLdOKFSvUpUuXRm/D7XZr27Ztio+P90OFAIALgV9ndg888ICWLFmizMxMtW7dWgUFBZIkl8uliy66SJI0ZswYXXrppUpPT5ckzZkzR1deeaWSkpJUWFioefPmac+ePbrvvvv8WSoAwGJ+DbtXXnlFkjRkyJAayxctWqRx48ZJkvLz8xUU9NME89ixY5owYYIKCgrUpk0bpaam6ssvv1TPnj39WSoAwGIBu0AlUIqLi+VyuZq7DABAE/nyAhWejQkAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsB5hBwCwHmEHALAeYQcAsJ5fw+6VV15Rnz59FBUVpaioKA0cOFAfffRRnf0zMjLkOE6NFhER4c8SAQAXgBB/brxjx4566qmn1L17dxlj9Pe//10jR47U5s2b1atXr1rHREVFKScnx/vZcRx/lggAuAD4NexGjBhR4/OTTz6pV155RV999VWdYec4juLi4hq8j/LycpWXl3s/FxUVnVuxAIDzijHGZ9sK2G92brdbb731lo4fP66BAwfW2a+0tFSJiYlKSEjQyJEjlZ2dXe9209PT5XK5vK1Tp06+Lh0A0AyOHDnis205xpfRWYtt27Zp4MCBOnnypFq1aqUlS5Zo+PDhtfZdt26dvvvuO/Xp00dFRUV65plntGbNGmVnZ6tjx461jjlzZldYWKjExETl5+fL5XL55TuhpuLiYiUkJGjv3r2Kiopq7nKsx/EOLI534BUVFalTp046duyYoqOjfbJNv4ddRUWF8vPzVVRUpH/961967bXXtHr1avXs2fMXx1ZWVuqyyy7TqFGj9MQTTzRof8XFxXK5XCoqKuIPM0A45oHF8Q4sjnfg+eOY+/U3O0kKCwtTUlKSJCk1NVUbNmzQCy+8oAULFvzi2NDQUKWkpCg3N9ffZQIALBbw++w8Hk+N0471cbvd2rZtm+Lj4/1cFQDAZn6d2c2aNUvDhg1Tp06dVFJSoiVLlmjVqlX65JNPJEljxozRpZdeqvT0dEnSnDlzdOWVVyopKUmFhYWaN2+e9uzZo/vuu6/B+wwPD9fs2bMVHh7ul++Es3HMA4vjHVgc78DzxzH362929957r5YvX64DBw7I5XKpT58+mjFjhq699lpJ0pAhQ9S5c2dlZGRIkv74xz9q6dKlKigoUJs2bZSamqr//u//VkpKir9KBABcAPx+gQoAAM2NZ2MCAKxH2AEArEfYAQCsR9gBAKxnRdgdPXpUd911l6KiohQdHa17771XpaWl9Y4ZMmTIWa8TmjRpUoAqbnlefvllde7cWRERERowYIC+/vrrOvvyqqamWbNmjUaMGKEOHTrIcRy9++679fZftWrVWcfbcRwVFBQEpuAWLD09XWlpaWrdurViY2N1880313jrSm34+26a5nr1m9+foBIId911lw4cOKDPPvtMlZWVGj9+vCZOnKglS5bUO27ChAmaM2eO93NkZKS/S22R/vnPf+rBBx/U/PnzNWDAAD3//PO6/vrrlZOTo9jY2FrH8Kqmc3f8+HFdfvnluueee3TLLbc0eFxOTk6NRyvV9e8GP1m9erUeeOABpaWlqaqqSn/605903XXXafv27br44ovrHMff97lrtle/mRZu+/btRpLZsGGDd9lHH31kHMcx+/fvr3Pc4MGDzdSpUwNQYcvXv39/88ADD3g/u91u06FDB5Oenl5r/0WLFhmXyxWg6uwmySxbtqzePitXrjSSzLFjxwJSk80OHTpkJJnVq1fX2Ye/b99r06aNee2112pd56vj3eJPY65bt07R0dG64oorvMuGDh2qoKAgrV+/vt6xb7zxhtq1a6fevXtr1qxZKisr83e5LU5FRYWysrI0dOhQ77KgoCANHTpU69atq3NcY1/VhKbr27ev4uPjde211+qLL75o7nJapNPvw2zbtm29/fj79g1/vfqtNi0+7AoKCs46XRMSEqK2bdvW+5vFnXfeqcWLF2vlypWaNWuWXn/9dY0ePdrf5bY4hw8fltvtVvv27Wssb9++fZ3HNzk5WQsXLlRmZqYWL14sj8ejq666Svv27QtEyRec+Ph4zZ8/X++8847eeecdJSQkaMiQIdq0aVNzl9aieDweTZs2TVdffbV69+5dZz/+vptu27ZtatWqlcLDwzVp0iQtW7aszjfh+Ox4N3lu6CczZswwkuptO3bsME8++aTp0aPHWeNjYmLMX//61wbvb/ny5UaSyc3N9eXXaPH2799vJJkvv/yyxvKHH37Y9O/fv0HbqKioMN26dTN//vOf/VGi1dSA05i1GTRokBk9erTvC7LYpEmTTGJiotm7d2+jxvH33Xjl5eXmu+++Mxs3bjQzZ8407dq1M9nZ2Q0ae67H+7y9QGX69OkaN25cvX26du2quLg4HTp0qMbyqqoqHT16VHFxcQ3e34ABAyRJubm56tatW6PrtVW7du0UHBysgwcP1lh+8ODBBh9fXtUUeP3799fatWubu4wWY8qUKXr//fe1Zs2aOl8UXRf+vhuvOV79dt6exoyJidGvfvWreltYWJgGDhyowsJCZWVleceuWLFCHo/HG2ANsWXLFknidUJnCAsLU2pqqpYvX+5d5vF4tHz58nrPsf8cr2oKvC1btnC8G8AYoylTpmjZsmVasWKFunTp0uht8PfddAF59ds5zEDPOzfccINJSUkx69evN2vXrjXdu3c3o0aN8q7ft2+fSU5ONuvXrzfGGJObm2vmzJljNm7caPLy8kxmZqbp2rWrGTRoUHN9hfPaW2+9ZcLDw01GRobZvn27mThxoomOjjYFBQXGGGPuvvtuM3PmTG//xx9/3HzyySdm165dJisry9xxxx0mIiKiwacpLnQlJSVm8+bNZvPmzUaSefbZZ83mzZvNnj17jDHGzJw509x9993e/s8995x59913zXfffWe2bdtmpk6daoKCgsznn3/eXF+hxZg8ebJxuVxm1apV5sCBA95WVlbm7cPft2/NnDnTrF692uTl5ZmtW7eamTNnGsdxzKeffmqM8d/xtiLsjhw5YkaNGmVatWploqKizPjx401JSYl3fV5enpFkVq5caYwxJj8/3wwaNMi0bdvWhIeHm6SkJPPwww+boqKiZvoG578XX3zRdOrUyYSFhZn+/fubr776yrtu8ODBZuzYsd7P06ZN8/Zt3769GT58uNm0aVMzVN0ynb6V4Mx2+hiPHTvWDB482Nv/6aefNt26dTMRERGmbdu2ZsiQIWbFihXNU3wLU9txlmQWLVrk7cPft2/dc889JjEx0YSFhZmYmBjz29/+1ht0xvjvePOKHwCA9c7b3+wAAPAVwg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYD3CDgBgPcIOAGA9wg4AYL3/D2HhImiS5uG8AAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-Table:\n",
            "[[1561.37485047 1546.18580583 1532.78506635 1518.4478804 ]\n",
            " [1287.86696227 1547.40892918 1304.61121036 1536.11808425]\n",
            " [1539.65997269 1562.17814263 1539.90537436 1462.03202379]\n",
            " [1543.9303476  1547.67646191 1559.9210752  1538.36937268]\n",
            " [1565.08209931 1556.18030483 1474.57662919 1471.95876543]\n",
            " [1547.5940324  1557.98196255 1517.65770394 1542.37069781]\n",
            " [1410.37176621 1471.6244185  1424.91785582 1565.79996714]\n",
            " [1541.02967856 1547.63294855 1515.39895888 1526.89245254]\n",
            " [1564.71178108 1547.47356227 1522.25969236 1550.78675817]\n",
            " [1429.11159507 1256.08395223 1516.36342169 1545.51980487]\n",
            " [1547.70588891 1527.08554658 1456.9594502  1306.34745389]\n",
            " [1542.9534447  1473.60931063 1187.77943549 1492.63568481]\n",
            " [1293.85883326 1524.80528817 1437.53823458 1547.71342206]\n",
            " [1181.73602723 1395.54359857 1546.50912097 1421.52368551]\n",
            " [1565.08178326 1323.71137254 1534.05172873 1151.1811898 ]\n",
            " [1541.44181926 1436.53050547 1478.0409251  1541.4914595 ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the grid world environment\n",
        "environment = np.array([\n",
        "    [-1, -1, -1, -1],    # 0 represents empty cells\n",
        "    [-1, -1, -1, -1],    # -1 represents obstacles\n",
        "    [-1, -1, -1, 100],   # 100 represents the goal state\n",
        "    [-1, -1, -1, -1]\n",
        "])\n",
        "\n",
        "# Set the parameters\n",
        "num_states = environment.size\n",
        "num_actions = 4  # Up, Down, Left, Right\n",
        "learning_rate = 0.8\n",
        "discount_factor = 0.95\n",
        "num_episodes = 1000\n",
        "max_steps_per_episode = 100\n",
        "\n",
        "# Initialize the Q-table\n",
        "q_table = np.zeros((num_states, num_actions))\n",
        "\n",
        "# Create a figure for visualization\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "# Perform Q-learning\n",
        "for episode in range(num_episodes):\n",
        "    state = np.random.randint(0, num_states)\n",
        "    for step in range(max_steps_per_episode):\n",
        "        # Choose an action using the epsilon-greedy strategy\n",
        "        if np.random.rand() < 0.5:\n",
        "            action = np.argmax(q_table[state])\n",
        "        else:\n",
        "            action = np.random.randint(0, num_actions)\n",
        "\n",
        "        # Perform the action and observe the new state and reward\n",
        "        new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "        reward = environment.flatten()[new_state]\n",
        "\n",
        "        # Update the Q-value of the previous state-action pair\n",
        "        q_table[state, action] += learning_rate * (reward + discount_factor * np.max(q_table[new_state]) - q_table[state, action])\n",
        "\n",
        "        # Update the visualization\n",
        "        ax.cla()\n",
        "        ax.matshow(environment, cmap='cool')\n",
        "        ax.set_xticks([])\n",
        "        ax.set_yticks([])\n",
        "\n",
        "        # Draw the agent's current position\n",
        "        agent_x, agent_y = divmod(state, environment.shape[1])\n",
        "        ax.plot(agent_y, agent_x, marker='o', color='red', markersize=20)\n",
        "\n",
        "        # Draw the goal position\n",
        "        goal_x, goal_y = divmod(new_state, environment.shape[1])\n",
        "        ax.plot(goal_y, goal_x, marker='*', color='gold', markersize=20)\n",
        "\n",
        "        # Add a pause to the visualization\n",
        "        plt.pause(0.1)\n",
        "\n",
        "        state = new_state\n",
        "\n",
        "        # Check if the goal state is reached\n",
        "        if reward == 100:\n",
        "            break\n",
        "\n",
        "# Test the learned policy\n",
        "state = 0  # Starting state\n",
        "steps = 0\n",
        "done = False\n",
        "\n",
        "while not done:\n",
        "    action = np.argmax(q_table[state])\n",
        "    new_state = np.where(environment.flatten() == 100)[0][0]\n",
        "    reward = environment.flatten()[new_state]\n",
        "\n",
        "    state = new_state\n",
        "    steps += 1\n",
        "\n",
        "    # Update the visualization\n",
        "    ax.cla()\n",
        "    ax.matshow(environment, cmap='cool')\n",
        "    ax.set_xticks([])\n",
        "    ax.set_yticks([])\n",
        "\n",
        "    # Draw the agent's current position\n",
        "    agent_x, agent_y = divmod(state, environment.shape[1])\n",
        "    ax.plot(agent_y, agent_x, marker='o', color='red', markersize=20)\n",
        "\n",
        "    # Draw the goal position\n",
        "    goal_x, goal_y = divmod(new_state, environment.shape[1])\n",
        "    ax.plot(goal_y, goal_x, marker='*', color='gold', markersize=20)\n",
        "\n",
        "    # Add a pause to the visualization\n",
        "    plt.pause(0.1)\n",
        "\n",
        "    if reward == 100 or steps >= max_steps_per_episode:\n",
        "        done = True\n",
        "\n",
        "# Print the learned Q-table\n",
        "print(\"Learned Q-Table:\")\n",
        "print(q_table)\n",
        "\n",
        "# Show the final visualization\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        },
        "id": "2Yi5NJSTagch",
        "outputId": "fe98ae98-8222-439e-ff7d-b1ec223ab59c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Learned Q-Table:\n",
            "[[1739.60252628 1589.91237454 1635.87537129 1649.62170377]\n",
            " [1554.41137925 1647.02168043 1552.47322286 1726.85458734]\n",
            " [1527.12979582 1705.60393798 1736.54866582 1739.48597501]\n",
            " [1711.1912274  1684.26640594 1585.91686462 1663.80627163]\n",
            " [1738.32742656 1613.86097348 1669.14869571 1721.31766359]\n",
            " [1704.7089759  1609.41216595 1736.67910232 1647.18224844]\n",
            " [1580.70851917 1589.37034173 1739.78444578 1413.82546537]\n",
            " [1647.73527586 1739.49791094 1732.70184509 1709.27532419]\n",
            " [1572.80152934 1730.40704296 1618.58554809 1522.48077457]\n",
            " [1577.88291904 1703.44767659 1739.9370542  1591.66659712]\n",
            " [1708.07150118 1718.64841633 1730.11685479 1528.59243905]\n",
            " [1725.13564683 1726.24996806 1259.1336577  1439.58802148]\n",
            " [1733.80527424 1735.54256659 1729.48971875 1665.9596675 ]\n",
            " [1645.04148448 1738.12727863 1553.28575338 1739.50493189]\n",
            " [1674.49379792 1734.77223807 1672.89974966 1670.02576507]\n",
            " [1636.44483747 1377.89791295 1649.71490645 1739.89971592]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "V9WkeXf7u8pQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}