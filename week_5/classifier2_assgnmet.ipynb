{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a lot of parameters that are set by default when working with these classifiers. Intellisense in VS Code can help you dig into them. Adopt one of the ML Classification Techniques in this lesson and retrain models tweaking various parameter values. Build a notebook explaining why some changes help the model quality while others degrade it. Be detailed in your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the necessary libries \n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix,classification_report, precision_recall_curve\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "#importing the model libries\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>cuisine</th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>indian</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>indian</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 382 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 cuisine  almond  angelica  anise  anise_seed  apple  \\\n",
       "0           0  indian       0         0      0           0      0   \n",
       "1           1  indian       1         0      0           0      0   \n",
       "2           2  indian       0         0      0           0      0   \n",
       "3           3  indian       0         0      0           0      0   \n",
       "4           4  indian       0         0      0           0      0   \n",
       "\n",
       "   apple_brandy  apricot  armagnac  ...  whiskey  white_bread  white_wine  \\\n",
       "0             0        0         0  ...        0            0           0   \n",
       "1             0        0         0  ...        0            0           0   \n",
       "2             0        0         0  ...        0            0           0   \n",
       "3             0        0         0  ...        0            0           0   \n",
       "4             0        0         0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 382 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading the dataset\n",
    "cuisines_df = pd.read_csv(\"cleaned_cuisines.csv\")\n",
    "cuisines_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    indian\n",
       "1    indian\n",
       "2    indian\n",
       "3    indian\n",
       "4    indian\n",
       "Name: cuisine, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Divide the X and y coordinates into two dataframes for training. cuisine can be the labels dataframe:\n",
    "\n",
    "cuisines_label_df = cuisines_df['cuisine']\n",
    "cuisines_label_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>almond</th>\n",
       "      <th>angelica</th>\n",
       "      <th>anise</th>\n",
       "      <th>anise_seed</th>\n",
       "      <th>apple</th>\n",
       "      <th>apple_brandy</th>\n",
       "      <th>apricot</th>\n",
       "      <th>armagnac</th>\n",
       "      <th>artemisia</th>\n",
       "      <th>artichoke</th>\n",
       "      <th>...</th>\n",
       "      <th>whiskey</th>\n",
       "      <th>white_bread</th>\n",
       "      <th>white_wine</th>\n",
       "      <th>whole_grain_wheat_flour</th>\n",
       "      <th>wine</th>\n",
       "      <th>wood</th>\n",
       "      <th>yam</th>\n",
       "      <th>yeast</th>\n",
       "      <th>yogurt</th>\n",
       "      <th>zucchini</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 380 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   almond  angelica  anise  anise_seed  apple  apple_brandy  apricot  \\\n",
       "0       0         0      0           0      0             0        0   \n",
       "1       1         0      0           0      0             0        0   \n",
       "2       0         0      0           0      0             0        0   \n",
       "3       0         0      0           0      0             0        0   \n",
       "4       0         0      0           0      0             0        0   \n",
       "\n",
       "   armagnac  artemisia  artichoke  ...  whiskey  white_bread  white_wine  \\\n",
       "0         0          0          0  ...        0            0           0   \n",
       "1         0          0          0  ...        0            0           0   \n",
       "2         0          0          0  ...        0            0           0   \n",
       "3         0          0          0  ...        0            0           0   \n",
       "4         0          0          0  ...        0            0           0   \n",
       "\n",
       "   whole_grain_wheat_flour  wine  wood  yam  yeast  yogurt  zucchini  \n",
       "0                        0     0     0    0      0       0         0  \n",
       "1                        0     0     0    0      0       0         0  \n",
       "2                        0     0     0    0      0       0         0  \n",
       "3                        0     0     0    0      0       0         0  \n",
       "4                        0     0     0    0      0       1         0  \n",
       "\n",
       "[5 rows x 380 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Drop that Unnamed: 0 column and the cuisine column, calling drop(). Save the rest of the data as trainable features:\n",
    "\n",
    "cuisines_feature_df = cuisines_df.drop(['Unnamed: 0', 'cuisine'], axis=1)\n",
    "cuisines_feature_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 10\n",
    "# Create different classifiers.\n",
    "classifiers = {\n",
    "    'Linear SVC': SVC(kernel='linear', C=C, probability=True,random_state=0),\n",
    "    'KNN classifier': KNeighborsClassifier(C),\n",
    "    'SVC':SVC(),\n",
    "    'RFST':RandomForestClassifier(n_estimators= 100),\n",
    "    'ADA':AdaBoostClassifier(n_estimators=100)\n",
    "\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************\n",
      "Accuracy (train) for Linear SVC: 78.2% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.66      0.70      0.68       249\n",
      "      indian       0.90      0.92      0.91       238\n",
      "    japanese       0.77      0.75      0.76       242\n",
      "      korean       0.81      0.75      0.78       230\n",
      "        thai       0.78      0.80      0.79       240\n",
      "\n",
      "    accuracy                           0.78      1199\n",
      "   macro avg       0.79      0.78      0.78      1199\n",
      "weighted avg       0.78      0.78      0.78      1199\n",
      "\n",
      "************************************\n",
      "Accuracy (train) for KNN classifier: 72.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.70      0.69      0.69       249\n",
      "      indian       0.87      0.77      0.82       238\n",
      "    japanese       0.62      0.83      0.71       242\n",
      "      korean       0.86      0.56      0.68       230\n",
      "        thai       0.66      0.75      0.70       240\n",
      "\n",
      "    accuracy                           0.72      1199\n",
      "   macro avg       0.74      0.72      0.72      1199\n",
      "weighted avg       0.74      0.72      0.72      1199\n",
      "\n",
      "************************************\n",
      "Accuracy (train) for SVC: 81.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.70      0.71      0.71       249\n",
      "      indian       0.91      0.89      0.90       238\n",
      "    japanese       0.81      0.80      0.80       242\n",
      "      korean       0.88      0.78      0.83       230\n",
      "        thai       0.77      0.88      0.82       240\n",
      "\n",
      "    accuracy                           0.81      1199\n",
      "   macro avg       0.82      0.81      0.81      1199\n",
      "weighted avg       0.81      0.81      0.81      1199\n",
      "\n",
      "************************************\n",
      "Accuracy (train) for RFST: 83.4% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.80      0.78      0.79       249\n",
      "      indian       0.89      0.91      0.90       238\n",
      "    japanese       0.86      0.81      0.84       242\n",
      "      korean       0.83      0.81      0.82       230\n",
      "        thai       0.78      0.86      0.82       240\n",
      "\n",
      "    accuracy                           0.83      1199\n",
      "   macro avg       0.84      0.83      0.83      1199\n",
      "weighted avg       0.83      0.83      0.83      1199\n",
      "\n",
      "************************************\n",
      "Accuracy (train) for ADA: 70.1% \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.61      0.45      0.52       249\n",
      "      indian       0.89      0.84      0.87       238\n",
      "    japanese       0.63      0.70      0.67       242\n",
      "      korean       0.63      0.74      0.68       230\n",
      "        thai       0.75      0.78      0.76       240\n",
      "\n",
      "    accuracy                           0.70      1199\n",
      "   macro avg       0.70      0.70      0.70      1199\n",
      "weighted avg       0.70      0.70      0.70      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_classifiers = len(classifiers)\n",
    "\n",
    "for index, (name, classifier) in enumerate(classifiers.items()):\n",
    "    classifier.fit(X_train, np.ravel(y_train))\n",
    "\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print('************************************')\n",
    "    print(\"Accuracy (train) for %s: %0.1f%% \" % (name, accuracy * 100))\n",
    "    print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let select one out of the four algortihms to see the difference when changing some of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost_classifier (train): 70.05838198498749\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.61      0.45      0.52       249\n",
      "      indian       0.89      0.84      0.87       238\n",
      "    japanese       0.63      0.70      0.67       242\n",
      "      korean       0.63      0.74      0.68       230\n",
      "        thai       0.75      0.78      0.76       240\n",
      "\n",
      "    accuracy                           0.70      1199\n",
      "   macro avg       0.70      0.70      0.70      1199\n",
      "weighted avg       0.70      0.70      0.70      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initial estimator\n",
    "classifier = AdaBoostClassifier(n_estimators=100)\n",
    "classifier.fit(X_train,np.ravel(y_train))\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Adaboost_classifier (train): {accuracy * 100}')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost_classifier (train): 60.46705587989991\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.55      0.27      0.36       249\n",
      "      indian       0.83      0.85      0.84       238\n",
      "    japanese       0.51      0.50      0.51       242\n",
      "      korean       0.49      0.74      0.59       230\n",
      "        thai       0.66      0.69      0.67       240\n",
      "\n",
      "    accuracy                           0.60      1199\n",
      "   macro avg       0.61      0.61      0.59      1199\n",
      "weighted avg       0.61      0.60      0.59      1199\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initial estimator\n",
    "classifier = AdaBoostClassifier(n_estimators=200)\n",
    "classifier.fit(X_train,np.ravel(y_train))\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Adaboost_classifier (train): {accuracy * 100}')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**estimator**\n",
    "\n",
    "An estimator is a mathematical model or algorithm that learns from data in order to make predictions or classify new instances in machine learning. In the context of a classifier, an estimator is a specific algorithm or model used for classification tasks.\n",
    "\n",
    "The classification process begins with training the estimator on a labeled dataset, where each instance is assigned a known class label. The estimator's goal is to learn patterns and relationships in the data that can be used to accurately classify previously unseen instances.\n",
    "\n",
    "**result interpretation**\n",
    "\n",
    "we can see from the above result when we try to increase the estimator vaules the accuracy result tends to reduce, which might be because of overfitting. Overfitting occurs when a model becomes too complex and starts to memorize the training data instead of learning general patterns that can be applied to unseen data.\n",
    "\n",
    "but below are some possible reasons why the result tends to decrease:\n",
    "Overfitting: As the number of estimators increases, the model becomes more complex and has a higher capacity to fit the training data. If the number of estimators is set too high, the model may start to overfit by focusing too much on the idiosyncrasies of the training data, resulting in poor generalization to new data.\n",
    "\n",
    "Insufficient regularization: AdaBoost uses a technique called \"boosting\" to combine multiple weak learners (estimators) into a strong ensemble model. Regularization is important in AdaBoost to prevent overfitting. If the regularization parameters are not properly tuned, increasing the number of estimators can exacerbate overfitting and lead to a decrease in accuracy.\n",
    "\n",
    "Limited training data: If the training dataset is relatively small, increasing the number of estimators might lead to overfitting. With a limited amount of data, the model may struggle to find meaningful patterns and end up memorizing noise or outliers instead.\n",
    "\n",
    "Lack of diversity among estimators: AdaBoost relies on combining weak learners that are diverse and complementary. Each estimator should focus on different aspects of the data. If the additional 100 estimators added to the model do not bring sufficient diversity or introduce new insights, the overall performance might not improve and could even degrade.\n",
    "\n",
    "To address this issue, you can try the following steps:\n",
    "\n",
    "Regularization:\n",
    "\n",
    "Cross-validation: \n",
    "\n",
    "Feature engineering: \n",
    "\n",
    "Increase the training data: \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let try and increase the training size form 70:30 to 80:20\n",
    "X_train, X_test, y_train, y_test = train_test_split(cuisines_feature_df, cuisines_label_df, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost_classifier (train): 70.58823529411765\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.62      0.45      0.52       164\n",
      "      indian       0.86      0.87      0.87       162\n",
      "    japanese       0.66      0.60      0.63       162\n",
      "      korean       0.66      0.81      0.73       159\n",
      "        thai       0.71      0.80      0.75       152\n",
      "\n",
      "    accuracy                           0.71       799\n",
      "   macro avg       0.70      0.71      0.70       799\n",
      "weighted avg       0.70      0.71      0.70       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#initial estimator\n",
    "classifier = AdaBoostClassifier(n_estimators=100)\n",
    "classifier.fit(X_train,np.ravel(y_train))\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Adaboost_classifier (train): {accuracy * 100}')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost_classifier (train): 66.08260325406758\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     chinese       0.61      0.44      0.51       164\n",
      "      indian       0.84      0.79      0.81       162\n",
      "    japanese       0.60      0.59      0.60       162\n",
      "      korean       0.65      0.75      0.70       159\n",
      "        thai       0.61      0.74      0.67       152\n",
      "\n",
      "    accuracy                           0.66       799\n",
      "   macro avg       0.66      0.66      0.66       799\n",
      "weighted avg       0.66      0.66      0.66       799\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#increasing the estimator\n",
    "classifier = AdaBoostClassifier(n_estimators=200)\n",
    "classifier.fit(X_train,np.ravel(y_train))\n",
    "y_pred = classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print(f'Adaboost_classifier (train): {accuracy * 100}')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:**\n",
    "\n",
    "When the training size is increases to 80:20, and 200 estimator was passed the accurarcy increases with 66% instead of the 60% got when using the 70:30 train_test_split ratio. \n",
    "\n",
    "so we can say that option for addressing the issue of overfitting in Adaboost_classifier works for us, that is increasing the training sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
