## INTODUCTION TO  MACHINE LEARNING 
Before we dive deep into what machine learning is and its techniques, let’s start by introducing what artificial intelligence is. Many definitions were given by different researchers, among which are:

## Artificial interligence

![image.png](https://miro.medium.com/v2/resize:fit:1400/0*aqjYal-ng3JdAuR2)
Artificial intelligence (AI) is a capability of a computer or a robot controlled by a computer to perform tasks that normally require human intelligence and decision-making. Although no AI can perform the wide range of tasks that an ordinary human can, some AIs can match humans in specific tasks.

In another definition:

The replication of human intelligence processes by machines, particularly computer systems, is known as artificial intelligence.


Problem solving, learning, perception, language understanding, and reasoning are the fundamental components of artificial intelligence. The AI has many applications, among which are speech recognition, expert systems, natural language processing, and machine vision. but keep in mind at all times that AI is everywhere in our lives nowadays, as we can pin point the applications of the AI in the image below:

![image.png](https://miro.medium.com/v2/resize:fit:828/format:webp/0*kAVtVeO89m8gVdvI.png)


# What is Machine learning?
![image.png](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*DQkkUEh_Tkikxcqc.jpg)

Machine learning is a modern innovation that has improved a wide range of industrial and professional processes, as well as our daily lives. It is a subset of artificial intelligence (AI) centered on developing intelligent computer systems that can learn from available databases by employing statistical techniques. In this article, we’ll cover the following topics under machine learning:

`History of machine learning
Fairness of machine learning
Essential things to know when dealing with machine learning
The machine learning process
The classification of Machine learning techniques`

# **The History of Machine learning**

![image.png](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bPuA5sm3Vy5oEe9Z.jpeg)

The history of machine learning can be traced back to the mid-twentieth century, when researchers began investigating the possibility of creating machines that could learn from data. The perceptron algorithm, proposed by Frank Rosenblatt in 1958, was one of the first developments in this field.

However, advancement in machine learning was hampered at the time by a lack of data and computing power. With the development of new algorithms and the availability of more data and faster computers in the 1980s and 1990s, the field saw a resurgence of interest. Since then, machine learning has advanced significantly, particularly with the introduction of deep learning techniques in the 2010s. Machine learning is now used in a variety of applications, including image recognition and natural language processing, as well as self-driving cars and personalized recommendations.

# **Fairness of machine learning**

![image.png](https://miro.medium.com/v2/resize:fit:1400/format:webp/0*PUHYGbkulAigkp0l.jpg)

Fairness is the quality of being just, impartial, and unbiased. In the context of machine learning, fairness refers to the idea that algorithms and models should treat all individuals and groups equitably without perpetuating or amplifying existing biases in society.

Fairness in machine learning is an important topic because machine learning models can sometimes perpetuate or even reinforce societal biases. These biases can be introduced by the data used to train the models or by the algorithm design itself. For example, if the training data is mostly made up of lighter-skinned people, a facial recognition system may perform poorly on people with darker skin tones.

To address these issues, researchers and practitioners are working on methods to detect and mitigate bias in machine learning models. This includes techniques like data augmentation, which can help to increase the diversity of training data, and algorithmic fairness, which ensures that models treat all individuals and groups fairly. The goal is to ensure that machine learning is used responsibly and ethically, promoting equity and fairness for all.